{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from sklearn import svm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample number: 2000, feature dimensionality: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.541078</td>\n",
       "      <td>0.084685</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.835211</td>\n",
       "      <td>0.414565</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.463693</td>\n",
       "      <td>0.600649</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.215385</td>\n",
       "      <td>0.838101</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.402105</td>\n",
       "      <td>1.605083</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.595065</td>\n",
       "      <td>0.079514</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.604953</td>\n",
       "      <td>0.947740</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.126134</td>\n",
       "      <td>-0.553929</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.860798</td>\n",
       "      <td>1.610948</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.414678</td>\n",
       "      <td>1.456316</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.397625</td>\n",
       "      <td>0.155746</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.565912</td>\n",
       "      <td>0.975325</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.067310</td>\n",
       "      <td>0.495983</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.619337</td>\n",
       "      <td>2.851932</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.828322</td>\n",
       "      <td>2.976116</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.117955</td>\n",
       "      <td>1.444863</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.389761</td>\n",
       "      <td>2.291021</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.101924</td>\n",
       "      <td>0.893055</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.830972</td>\n",
       "      <td>1.777034</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.434833</td>\n",
       "      <td>0.752061</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.805434</td>\n",
       "      <td>0.164854</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.426851</td>\n",
       "      <td>2.141048</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.259535</td>\n",
       "      <td>1.291343</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.254166</td>\n",
       "      <td>0.046934</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.318841</td>\n",
       "      <td>1.979656</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.256755</td>\n",
       "      <td>1.495302</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.704866</td>\n",
       "      <td>1.227828</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.991478</td>\n",
       "      <td>1.123275</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.032857</td>\n",
       "      <td>0.481111</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.793147</td>\n",
       "      <td>1.161001</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>-1.455146</td>\n",
       "      <td>-0.120449</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>0.075038</td>\n",
       "      <td>-0.934204</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>-1.065841</td>\n",
       "      <td>-0.542819</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>-0.531028</td>\n",
       "      <td>-1.292279</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>-0.353097</td>\n",
       "      <td>-0.800635</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>-1.601531</td>\n",
       "      <td>-1.158908</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>-0.961157</td>\n",
       "      <td>-1.006830</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>-0.779459</td>\n",
       "      <td>-1.194869</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>-1.200553</td>\n",
       "      <td>-0.605926</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>-1.995253</td>\n",
       "      <td>-1.131330</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>-1.414987</td>\n",
       "      <td>-1.031247</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>-0.314965</td>\n",
       "      <td>-0.705311</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>-1.961605</td>\n",
       "      <td>-1.580259</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>-1.820302</td>\n",
       "      <td>-0.993628</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>-0.823350</td>\n",
       "      <td>-0.301578</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>-0.979865</td>\n",
       "      <td>-0.751064</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>-1.002286</td>\n",
       "      <td>-1.291969</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>-1.201679</td>\n",
       "      <td>-0.519663</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>-0.865947</td>\n",
       "      <td>-0.044414</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>-0.595478</td>\n",
       "      <td>-0.257266</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>-1.296917</td>\n",
       "      <td>-0.443389</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>-0.314370</td>\n",
       "      <td>-1.250452</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>-1.123253</td>\n",
       "      <td>-1.168954</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>-0.997756</td>\n",
       "      <td>-0.905585</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>-0.809466</td>\n",
       "      <td>-1.105009</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>-1.447480</td>\n",
       "      <td>-1.052005</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>-0.575502</td>\n",
       "      <td>-0.672934</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>-0.756451</td>\n",
       "      <td>-1.472600</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>-0.898561</td>\n",
       "      <td>-0.703577</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>-1.483371</td>\n",
       "      <td>-0.827038</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature1  feature2  labels\n",
       "0     0.541078  0.084685     1.0\n",
       "1     1.835211  0.414565     1.0\n",
       "2     0.463693  0.600649     1.0\n",
       "3     0.215385  0.838101     1.0\n",
       "4     0.402105  1.605083     1.0\n",
       "5     0.595065  0.079514     1.0\n",
       "6     0.604953  0.947740     1.0\n",
       "7     1.126134 -0.553929     1.0\n",
       "8     0.860798  1.610948     1.0\n",
       "9     1.414678  1.456316     1.0\n",
       "10    0.397625  0.155746     1.0\n",
       "11    1.565912  0.975325     1.0\n",
       "12   -0.067310  0.495983     1.0\n",
       "13    1.619337  2.851932     1.0\n",
       "14    0.828322  2.976116     1.0\n",
       "15    1.117955  1.444863     1.0\n",
       "16   -0.389761  2.291021     1.0\n",
       "17    0.101924  0.893055     1.0\n",
       "18    1.830972  1.777034     1.0\n",
       "19    2.434833  0.752061     1.0\n",
       "20    0.805434  0.164854     1.0\n",
       "21    1.426851  2.141048     1.0\n",
       "22    2.259535  1.291343     1.0\n",
       "23    2.254166  0.046934     1.0\n",
       "24   -0.318841  1.979656     1.0\n",
       "25    0.256755  1.495302     1.0\n",
       "26    0.704866  1.227828     1.0\n",
       "27    1.991478  1.123275     1.0\n",
       "28    0.032857  0.481111     1.0\n",
       "29    0.793147  1.161001     1.0\n",
       "...        ...       ...     ...\n",
       "1970 -1.455146 -0.120449     2.0\n",
       "1971  0.075038 -0.934204     2.0\n",
       "1972 -1.065841 -0.542819     2.0\n",
       "1973 -0.531028 -1.292279     2.0\n",
       "1974 -0.353097 -0.800635     2.0\n",
       "1975 -1.601531 -1.158908     2.0\n",
       "1976 -0.961157 -1.006830     2.0\n",
       "1977 -0.779459 -1.194869     2.0\n",
       "1978 -1.200553 -0.605926     2.0\n",
       "1979 -1.995253 -1.131330     2.0\n",
       "1980 -1.414987 -1.031247     2.0\n",
       "1981 -0.314965 -0.705311     2.0\n",
       "1982 -1.961605 -1.580259     2.0\n",
       "1983 -1.820302 -0.993628     2.0\n",
       "1984 -0.823350 -0.301578     2.0\n",
       "1985 -0.979865 -0.751064     2.0\n",
       "1986 -1.002286 -1.291969     2.0\n",
       "1987 -1.201679 -0.519663     2.0\n",
       "1988 -0.865947 -0.044414     2.0\n",
       "1989 -0.595478 -0.257266     2.0\n",
       "1990 -1.296917 -0.443389     2.0\n",
       "1991 -0.314370 -1.250452     2.0\n",
       "1992 -1.123253 -1.168954     2.0\n",
       "1993 -0.997756 -0.905585     2.0\n",
       "1994 -0.809466 -1.105009     2.0\n",
       "1995 -1.447480 -1.052005     2.0\n",
       "1996 -0.575502 -0.672934     2.0\n",
       "1997 -0.756451 -1.472600     2.0\n",
       "1998 -0.898561 -0.703577     2.0\n",
       "1999 -1.483371 -0.827038     2.0\n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load two Gaussian dataset\n",
    "\n",
    "dict = sio.loadmat('dataset1')\n",
    "samples = dict['samples']\n",
    "labels = dict['labels']\n",
    "labels = np.reshape(labels, -1) #change 2d vector (n, 1) to 1d vector (n,)\n",
    "\n",
    "sample_num, sample_dim = samples.shape # N x D\n",
    "print(\"Sample number: %d, feature dimensionality: %d\" % (sample_num, sample_dim))\n",
    "\n",
    "col_names=[]\n",
    "for i in range(sample_dim):\n",
    "    str='feature%d'%(i+1)\n",
    "    col_names.append(str)\n",
    "col_names.append('labels')\n",
    "pandas.DataFrame(np.concatenate((samples, labels.reshape(sample_num,1)), axis=1), columns=col_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change class label from 1,2 to -1, 1\n",
    "labels = labels.astype(float)\n",
    "labels[labels==2] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot the dataset, with class labels\n",
    "\n",
    "plt.plot(samples[labels==1,0],samples[labels==1, 1],'ro')\n",
    "plt.plot(samples[labels==-1,0],samples[labels==-1, 1],'g^')\n",
    "plt.legend({'class 1', 'class -1'})\n",
    "plt.title('A toy dataset with two Gaussian distributions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the dataset into training and testing sets\n",
    "\n",
    "idx = list(range(sample_num)) # randomly shuffle indices\n",
    "np.random.shuffle(idx)  \n",
    "\n",
    "training_idx = idx[:int(sample_num/2)] # 50% training\n",
    "training_samples = samples[training_idx]\n",
    "training_labels = labels[training_idx]\n",
    "\n",
    "testing_idx = idx[int(sample_num/2):] # 50% testing\n",
    "testing_samples = samples[testing_idx]\n",
    "testing_labels = labels[testing_idx]\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "#plot the data set, with class labels\n",
    "plt.plot(training_samples[training_labels==1,0],training_samples[training_labels==1, 1],'ro')\n",
    "plt.plot(training_samples[training_labels==-1,0],training_samples[training_labels==-1, 1],'g^')\n",
    "plt.legend({'class 1', 'class 2'})\n",
    "plt.title('training set')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "#plot the data set, with class labels\n",
    "plt.plot(testing_samples[testing_labels==1,0],testing_samples[testing_labels==1, 1],'mo')\n",
    "plt.plot(testing_samples[testing_labels==-1,0],testing_samples[testing_labels==-1, 1],'c^')\n",
    "plt.legend({'class 1', 'class -1'})\n",
    "plt.title('testing set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two class Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoClassNaiveBayesClassifier(object):\n",
    "    \n",
    "    def __init__(self,sample_dim):\n",
    "        self.sample_dim = sample_dim\n",
    "        \n",
    "\n",
    "            \n",
    "    def train(self, training_samples, training_labels):\n",
    "        \n",
    "        #u = np.unique(training_labels)\n",
    "        #if len(u) != 2 or u[0] != -1 or u[1] !=1:\n",
    "        #    raise Exception('Label range must be -1 and 1')\n",
    "            \n",
    "        sample_dim = self.sample_dim\n",
    "        sample_num = training_samples.shape[0]\n",
    "        \n",
    "        #initialize each dim mean and std, assuming Gaussian distribution\n",
    "        mean_list = np.zeros((sample_dim, 2))   # mean of class 1 and 2, for each dimension\n",
    "        std_list = np.zeros((sample_dim, 2))    # std of class 1 and 2, for each dimension\n",
    "        class_prior = np.zeros((2))\n",
    "        \n",
    "        #compute class prior\n",
    "        class_prior[0] = np.count_nonzero (training_labels == 1)/sample_num\n",
    "        class_prior[1] = np.count_nonzero (training_labels == -1)/sample_num\n",
    "        \n",
    "        #compute mean and std of each dim for each class\n",
    "        for d in range(sample_dim):\n",
    "            mean_list[d, 0] = np.mean(training_samples[training_labels==1, d])\n",
    "            mean_list[d, 1] = np.mean(training_samples[training_labels==-1, d])\n",
    "            std_list[d, 0] = np.std(training_samples[training_labels==1, d])\n",
    "            std_list[d, 1] = np.std(training_samples[training_labels==-1, d])\n",
    "        \n",
    "        \n",
    "        # store in object for testing phase\n",
    "        self.class_prior = class_prior\n",
    "        self.mean_list = mean_list\n",
    "        self.std_list = std_list\n",
    "        \n",
    "    \n",
    "    def test(self, testing_samples, testing_labels = None):\n",
    "            \n",
    "        sample_num = testing_samples.shape[0]\n",
    "        \n",
    "        #to store predict label of each sample\n",
    "        predicted_labels = np.zeros((sample_num))\n",
    "        \n",
    "        # get parameters computed during training phase\n",
    "        class_prior = self.class_prior\n",
    "        mean_list = self.mean_list\n",
    "        std_list = self.std_list\n",
    "        \n",
    "        for i in range(sample_num):\n",
    "            xi = testing_samples[i] # pick a sample\n",
    "            \n",
    "            xi_posterior_prob = [1, 1] # posterior of xi for class 1 and 2\n",
    "            \n",
    "            for d in range(self.sample_dim):\n",
    "                xi_prob1 = self.GaussianPDF(xi[d], mean_list[d,0], std_list[d, 0]) # multiply probabilities of dim d for class 1 \n",
    "                xi_posterior_prob[0] *= xi_prob1 \n",
    "                \n",
    "                xi_prob2 = self.GaussianPDF(xi[d], mean_list[d,1], std_list[d, 1]) # multiply probabilities of dim d for class 2\n",
    "                xi_posterior_prob[1] *= xi_prob2\n",
    "                \n",
    "            # take class prior into account\n",
    "            xi_posterior_prob[0] *= class_prior[0]\n",
    "            xi_posterior_prob[1] *= class_prior[1]\n",
    "            \n",
    "            if xi_posterior_prob[0] > xi_posterior_prob[1]:\n",
    "                predicted_labels [i] = 1\n",
    "            else:\n",
    "                predicted_labels [i] = -1\n",
    "                \n",
    "        #compute error rate\n",
    "        if testing_labels is not None:\n",
    "            error_rate = np.count_nonzero(testing_labels != predicted_labels)/sample_num\n",
    "        else:\n",
    "            error_rate = None\n",
    "        \n",
    "        return predicted_labels, error_rate\n",
    "    \n",
    "\n",
    "    def GaussianPDF(self, x, mean, std):\n",
    "        prob = 1/(2*math.pi*(std+np.finfo(float).eps)**2)*math.exp(-(x-mean)**2/(2*(std+np.finfo(float).eps)**2))\n",
    "        return prob\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform training and testing\n",
    "\n",
    "NBC = TwoClassNaiveBayesClassifier(sample_dim)\n",
    "NBC.train(training_samples, training_labels)\n",
    "predicted_labels, error_rate = NBC.test(testing_samples, testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot ground truth\n",
    "plt.plot(testing_samples[testing_labels==1,0], testing_samples[testing_labels==1, 1],'ro')\n",
    "plt.plot(testing_samples[testing_labels==-1,0], testing_samples[testing_labels==-1, 1],'g^')\n",
    "plt.legend({'class 1', 'class 2'})\n",
    "plt.title('ground truth')\n",
    "\n",
    "#plot prediction results\n",
    "plt.figure()\n",
    "plt.plot(testing_samples[predicted_labels==1,0],testing_samples[predicted_labels==1, 1],'mo')\n",
    "plt.plot(testing_samples[predicted_labels==-1,0],testing_samples[predicted_labels==-1, 1],'c^')\n",
    "plt.legend({'class 1', 'class -1'})\n",
    "plt.title('prediction results of NBC (error rate: %.03f)' % (error_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the confusion matrix\n",
    "\n",
    "confusion_matrix = np.zeros((2,2))\n",
    "class_labels = [-1, 1]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        confusion_matrix[i,j] = np.sum(np.logical_and(testing_labels == class_labels[i], predicted_labels == class_labels[j]))\n",
    "\n",
    "        \n",
    "pandas.DataFrame(confusion_matrix, index={\"true class1\", \"true class-1\"}, columns={'predicted class1', 'predicted class-1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform cross validation\n",
    "fold_num = 10\n",
    "fold_size = int(sample_num/fold_num)\n",
    "\n",
    "fold_error_rate = []\n",
    "for k in range(fold_num):\n",
    "    \n",
    "    fold_beg = k*fold_size # start index of testing samples in each fold\n",
    "    fold_end = (k+1)*fold_size     # end idex of testing samples in each fold\n",
    "    \n",
    "    testing_samples_cv = samples[idx[fold_beg:fold_end]]\n",
    "    testing_labels_cv = labels[idx[fold_beg:fold_end]]\n",
    "    \n",
    "    training_samples_cv = np.delete(samples,idx[fold_beg:fold_end], 0)\n",
    "    training_labels_cv = np.delete(labels, idx[fold_beg:fold_end], 0)\n",
    "    \n",
    "    NBC.train(training_samples_cv, training_labels_cv)\n",
    "    predicted_labels, error_rate = NBC.test(testing_samples_cv, testing_labels_cv)\n",
    "    \n",
    "    fold_error_rate.append(error_rate)\n",
    "    \n",
    "print(\"error rate of each fold: \", fold_error_rate)\n",
    "print('mean error of all fold:', np.mean(fold_error_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressor(object):\n",
    "    \n",
    "    def __init__(self, sample_dim):\n",
    "        self.sample_dim = sample_dim\n",
    "        \n",
    "    def train(self, training_samples, training_labels, regularizer = 0, show_w=True):\n",
    "        \n",
    "        sample_num = training_samples.shape[0]\n",
    "        \n",
    "        # check labels range (-1, 1)\n",
    "        u = np.unique(training_labels)\n",
    "        if len(u) != 2 or u[0] != -1 or u[1] !=1:\n",
    "            raise Exception('Label range must be -1 and 1')\n",
    "            \n",
    "        # append a 1 to the end of each sample to form extended sample [x 1]'\n",
    "        X = np.concatenate((training_samples, np.ones((sample_num,1))), axis=1) \n",
    "        \n",
    "        XX = X.T.dot(X)\n",
    "        Xy = X.T.dot(training_labels)\n",
    "        w = np.linalg.inv(XX + regularizer*np.eye(XX.shape[0])).dot(Xy)\n",
    "        \n",
    "        self.w = w\n",
    "        \n",
    "        if show_w:\n",
    "            print('(w,b)=',w)\n",
    "        \n",
    "        return w\n",
    "    def test(self, testing_samples, testing_labels = None):\n",
    "        \n",
    "        sample_num = testing_samples.shape[0]\n",
    "        \n",
    "            \n",
    "         # append a 1 to the end of each sample to form extended sample [x 1]'\n",
    "        X = np.concatenate((testing_samples, np.ones((sample_num,1))), axis=1) \n",
    "        \n",
    "        y = X.dot(self.w)\n",
    "        \n",
    "        predicted_labels = np.ones(sample_num)\n",
    "        predicted_labels[y<0] = -1\n",
    "\n",
    "        #compute error rate\n",
    "        if testing_labels is not None:\n",
    "            error_rate = np.count_nonzero(testing_labels != predicted_labels)/sample_num\n",
    "        else:\n",
    "            error_rate = None\n",
    "        \n",
    "        return predicted_labels, error_rate\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first without regularization\n",
    "LR = LinearRegressor(sample_dim)\n",
    "w = LR.train(training_samples, training_labels)\n",
    "predicted_labels, error_rate = LR.test(testing_samples, testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot ground truth of testing samples\n",
    "plt.plot(testing_samples[testing_labels==1,0], testing_samples[testing_labels==1, 1],'ro')\n",
    "plt.plot(testing_samples[testing_labels==-1,0], testing_samples[testing_labels==-1, 1],'g^')\n",
    "plt.legend({'class 1', 'class -1'})\n",
    "plt.title('ground truth')\n",
    "\n",
    "#plot prediction results\n",
    "plt.figure()\n",
    "plt.plot(testing_samples[predicted_labels==1,0],testing_samples[predicted_labels==1, 1],'mo')\n",
    "plt.plot(testing_samples[predicted_labels==-1,0],testing_samples[predicted_labels==-1, 1],'c^')\n",
    "plt.legend({'class 1', 'class -1'})\n",
    "plt.title('prediction results of LR (error rate: %.03f)' % (error_rate))\n",
    "\n",
    "# plot decision boundary\n",
    "if sample_dim ==2:\n",
    "    minx = min(testing_samples[:, 0])\n",
    "    maxx = max(testing_samples[:, 0]) \n",
    "    \n",
    "    x = np.linspace(minx, maxx, testing_samples.shape[0])\n",
    "    y = -(w[0]*x+w[2])/w[1]\n",
    "    \n",
    "    plt.plot(x,y,'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix of LR\n",
    "confusion_matrix = np.zeros((2,2))\n",
    "class_labels = [-1, 1]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        confusion_matrix[i,j] = np.sum(np.logical_and(testing_labels == class_labels[i], predicted_labels == class_labels[j]))\n",
    "\n",
    "        \n",
    "pandas.DataFrame(confusion_matrix, index={\"true class1\", \"true class-1\"}, columns={'predicted class1', 'predicted class-1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smaller training set, without regularization\n",
    "LR.train(training_samples[:10], training_labels[:10])\n",
    "predicted_labels, error_rate = LR.test(testing_samples, testing_labels)\n",
    "print('error rate: %.03f' % (error_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smaller training set, with regularization\n",
    "LR.train(training_samples[:10], training_labels[:10], regularizer=10)\n",
    "predicted_labels, error_rate = LR.test(testing_samples, testing_labels)\n",
    "print('error rate: %.03f' % (error_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuning parameter regularizer to have the best performance\n",
    "\n",
    "# show error rate change v.s. regularizer (0 - 100)\n",
    "\n",
    "ER = []\n",
    "for regularizer in range(100):\n",
    "    LR.train(training_samples[:10], training_labels[:10], regularizer=regularizer, show_w=False)\n",
    "    predicted_labels, error_rate = LR.test(testing_samples, testing_labels)\n",
    "    ER.append(error_rate)\n",
    "    \n",
    "plt.plot(list(range(100)), ER,'-x')\n",
    "plt.xlabel('regularizer')\n",
    "plt.ylabel('error rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try a larger regularizer range, i.e. (0 - 1000)\n",
    "\n",
    "ER = []\n",
    "for regularizer in range(1000):\n",
    "    LR.train(training_samples[:10], training_labels[:10], regularizer=regularizer, show_w=False)\n",
    "    predicted_labels, error_rate = LR.test(testing_samples, testing_labels)\n",
    "    ER.append(error_rate)\n",
    "    \n",
    "plt.plot(list(range(1000)), ER,'-x')\n",
    "plt.xlabel('regularizer')\n",
    "plt.ylabel('error rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform cross validation\n",
    "fold_num = 10\n",
    "fold_size = int(sample_num/fold_num)\n",
    "\n",
    "fold_error_rate = []\n",
    "for k in range(fold_num):\n",
    "    \n",
    "    fold_beg = k*fold_size # start index of testing samples in each fold\n",
    "    fold_end = (k+1)*fold_size     # end idex of testing samples in each fold\n",
    "    \n",
    "    testing_samples_cv = samples[idx[fold_beg:fold_end]]\n",
    "    testing_labels_cv = labels[idx[fold_beg:fold_end]]\n",
    "    \n",
    "    training_samples_cv = np.delete(samples,idx[fold_beg:fold_end], 0)\n",
    "    training_labels_cv = np.delete(labels, idx[fold_beg:fold_end], 0)\n",
    "    \n",
    "    LR.train(training_samples_cv, training_labels_cv, show_w=False)\n",
    "    predicted_labels, error_rate = LR.test(testing_samples_cv, testing_labels_cv)\n",
    "    \n",
    "    fold_error_rate.append(error_rate)\n",
    "    \n",
    "print(\"error rate of each fold: \", fold_error_rate)\n",
    "print('mean error of all fold:', np.mean(fold_error_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare performances of NBC and LR for different training data size\n",
    "\n",
    "nbc_errors = []\n",
    "lr_errors = []\n",
    "ts_start, ts_stop, ts_step = 10, 100, 2 #  training data size list\n",
    "for ts in range(ts_start, ts_stop, ts_step):\n",
    "    \n",
    "    #divide training and testing\n",
    "    np.random.shuffle(idx) \n",
    "    training_idx = idx[:int(ts)]\n",
    "    training_samples = samples[training_idx]\n",
    "    training_labels = labels[training_idx]\n",
    "\n",
    "    testing_idx = idx[int(ts):]\n",
    "    testing_samples = samples[testing_idx]\n",
    "    testing_labels = labels[testing_idx]\n",
    "    \n",
    "    #NBC\n",
    "    NBC.train(training_samples, training_labels)\n",
    "    predicted_labels, error_rate = NBC.test(testing_samples, testing_labels)\n",
    "    nbc_errors.append(error_rate)\n",
    "    \n",
    "    #LR\n",
    "    LR.train(training_samples, training_labels, show_w=False)\n",
    "    predicted_labels, error_rate = LR.test(testing_samples, testing_labels)\n",
    "    lr_errors.append(error_rate)\n",
    "    \n",
    "\n",
    "plt.plot(list(range(ts_start, ts_stop, ts_step)), nbc_errors, 'r-o')\n",
    "plt.plot(list(range(ts_start, ts_stop, ts_step)), lr_errors, 'b-^')\n",
    "plt.legend({'NBC errors', 'LR errors'})\n",
    "plt.xlabel('training set size')\n",
    "plt.ylabel('error rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearDiscriminantAnalysis(object):\n",
    "    \n",
    "    def __init__(self, sample_dim):\n",
    "        self.sample_dim = sample_dim\n",
    "        \n",
    "    def train(self, training_samples, training_labels):\n",
    "        \n",
    "        sample_num = training_samples.shape[0]\n",
    "        \n",
    "        # check labels  {-1, 1}\n",
    "        u = np.unique(training_labels)\n",
    "        if len(u) != 2 or u[0] != -1 or u[1] !=1:\n",
    "            raise Exception('Label range must be -1 and 1')\n",
    "            \n",
    "        # mean vector of each class before projection\n",
    "        u0 = np.mean(training_samples[training_labels==1], axis=0)\n",
    "        u1 = np.mean(training_samples[training_labels==-1], axis=0)\n",
    "        \n",
    "        # covariance matrix for each class before projection\n",
    "        Cov0 = np.zeros((self.sample_dim, self.sample_dim))\n",
    "        Cov1 = np.zeros((self.sample_dim, self.sample_dim))\n",
    "        for i in range(sample_num):\n",
    "\n",
    "            if training_labels[i]==1:\n",
    "                Cov0 += np.outer(training_samples[i]-u0, training_samples[i]-u0) #correction: PPT formula is wrong!\n",
    "            elif training_labels[i]==-1:\n",
    "                Cov1 += np.outer(training_samples[i]-u1, training_samples[i]-u1)\n",
    "            else:\n",
    "                raise Exception('Unrecognized class label!')\n",
    "                \n",
    "        # within class scatter matrix\n",
    "        Sw = Cov0/np.count_nonzero(training_labels==1) + Cov1/np.count_nonzero(training_labels==-1) \n",
    "        \n",
    "        # optimal projection vector\n",
    "        w = np.dot(np.linalg.inv(Sw), u0-u1)\n",
    "        \n",
    "        # mean of each class after projection\n",
    "        m0 = np.dot(w, u0)\n",
    "        m1 = np.dot(w, u1)\n",
    "        \n",
    "        #save variables for testing stage\n",
    "        self. w = w\n",
    "        self. m0 = m0\n",
    "        self. m1 = m1\n",
    "        \n",
    "        return w, u0, u1\n",
    "    def test(self, testing_samples, testing_labels = None):\n",
    "        \n",
    "        sample_num = testing_samples.shape[0]\n",
    "        \n",
    "        #restore variables\n",
    "        w = self.w\n",
    "        m0 = self.m0\n",
    "        m1 = self.m1\n",
    "        \n",
    "        predicted_labels = np.zeros(sample_num)\n",
    "        for i in range(sample_num):\n",
    "            x = testing_samples[i]\n",
    "            \n",
    "            # project to w\n",
    "            xp = np.dot(w, x)\n",
    "            \n",
    "            # compute distance to class 0 and class 1\n",
    "            d0 = np.abs(xp-m0)\n",
    "            d1 = np.abs(xp-m1)\n",
    "            \n",
    "            # classify to nearest class\n",
    "            if d0<d1:\n",
    "                predicted_labels[i] = 1\n",
    "            else:\n",
    "                predicted_labels[i] = -1\n",
    "\n",
    "        #compute error rate\n",
    "        if testing_labels is not None:\n",
    "            error_rate = np.count_nonzero(testing_labels != predicted_labels)/sample_num\n",
    "        else:\n",
    "            error_rate = None\n",
    "        \n",
    "        return predicted_labels, error_rate\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first without regularization\n",
    "LDA = LinearDiscriminantAnalysis(sample_dim)\n",
    "w, u0, u1 = LDA.train(training_samples, training_labels)\n",
    "predicted_labels, error_rate = LDA.test(testing_samples, testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plot ground truth of testing samples\n",
    "plt.plot(testing_samples[testing_labels==1,0], testing_samples[testing_labels==1, 1],'ro')\n",
    "plt.plot(testing_samples[testing_labels==-1,0], testing_samples[testing_labels==-1, 1],'g^')\n",
    "plt.legend({'class 1', 'class -1'})\n",
    "plt.title('ground truth')\n",
    "\n",
    "#plot prediction results\n",
    "plt.figure()\n",
    "plt.plot(testing_samples[predicted_labels==1,0],testing_samples[predicted_labels==1, 1],'mo')\n",
    "plt.plot(testing_samples[predicted_labels==-1,0],testing_samples[predicted_labels==-1, 1],'c^')\n",
    "plt.legend({'class 1', 'class -1'})\n",
    "plt.title('prediction results of LDA (error rate: %.03f)' % (error_rate))\n",
    "\n",
    "#plot center after projection\n",
    "plt.plot(u0[0], u0[1], 'ko')\n",
    "plt.plot(u1[0], u1[1], 'k^')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(object):\n",
    "    \n",
    "    def __init__(self, sample_dim):\n",
    "        self.sample_dim = sample_dim\n",
    "        \n",
    "    def train(self, training_samples, training_labels, learning_rate=0.01, max_iterations=100):\n",
    "        \n",
    "        # check labels range (-1, 1)\n",
    "        \n",
    "        u = np.unique(training_labels)\n",
    "        if len(u) != 2 or u[0] != 0 or u[1] !=1:\n",
    "            raise Exception('Label range must be 0 and 1')\n",
    "                \n",
    "        sample_dim = self.sample_dim\n",
    "        sample_num = training_samples.shape[0]\n",
    "        \n",
    "        #init w and b\n",
    "        w = np.random.rand(sample_dim)\n",
    "        b = 0\n",
    "        \n",
    "        step = 0\n",
    "        while step<max_iterations:\n",
    "            \n",
    "            dw = np.zeros(sample_dim)\n",
    "            db = 0\n",
    "            \n",
    "            for i in range(sample_num):\n",
    "                \n",
    "                xi, yi = training_samples[i], training_labels[i]\n",
    "                \n",
    "                pi = 1-1/(1+np.exp(np.dot(w, xi)+b)) # p(yi=1|xi, w, b) in dw equation\n",
    "                \n",
    "                dw += (xi*yi - xi*pi)\n",
    "                db += (yi - pi)\n",
    "            \n",
    "            dw = -dw\n",
    "            db = -db\n",
    "            w -= learning_rate*dw\n",
    "            b -= learning_rate*db\n",
    "            \n",
    "            step += 1\n",
    "            \n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        return w, b\n",
    "    def test(self, testing_samples, testing_labels = None):\n",
    "        \n",
    "        sample_num = testing_samples.shape[0]\n",
    "        \n",
    "        #restore variables\n",
    "        w = self.w\n",
    "        b = self.b\n",
    "        \n",
    "        predicted_labels = np.zeros(sample_num)\n",
    "        for i in range(sample_num):\n",
    "            x = testing_samples[i]\n",
    "            \n",
    "            pi = 1-1/(1+np.exp(np.dot(w, x)+b)) # p(yi=1|xi, w, b)\n",
    "            \n",
    "            \n",
    "            # classify to nearest class\n",
    "            if pi<0.5:\n",
    "                predicted_labels[i] = 0\n",
    "            else:\n",
    "                predicted_labels[i] = 1\n",
    "\n",
    "        #compute error rate\n",
    "        if testing_labels is not None:\n",
    "            error_rate = np.count_nonzero(testing_labels != predicted_labels)/sample_num\n",
    "        else:\n",
    "            error_rate = None\n",
    "        \n",
    "        return predicted_labels, error_rate\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert labels from {-1, 1} to {0, 1}\n",
    "training_labels2 = training_labels.copy()\n",
    "training_labels2[training_labels2==-1] = 0\n",
    "testing_labels2 = testing_labels.copy()\n",
    "testing_labels2[testing_labels2==-1] = 0\n",
    "\n",
    "LogR = LogisticRegression(sample_dim)\n",
    "w,b = LogR.train(training_samples, training_labels2, learning_rate=0.01, max_iterations=10)\n",
    "predicted_labels, error_rate = LogR.test(testing_samples, testing_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot ground truth of testing samples\n",
    "plt.plot(testing_samples[testing_labels2==1,0], testing_samples[testing_labels2==1, 1],'ro')\n",
    "plt.plot(testing_samples[testing_labels2==0,0], testing_samples[testing_labels2==0, 1],'g^')\n",
    "plt.legend({'class 1', 'class 0'})\n",
    "plt.title('ground truth')\n",
    "\n",
    "#plot prediction results\n",
    "plt.figure()\n",
    "plt.plot(testing_samples[predicted_labels==1,0],testing_samples[predicted_labels==1, 1],'mo')\n",
    "plt.plot(testing_samples[predicted_labels==0,0],testing_samples[predicted_labels==0, 1],'c^')\n",
    "plt.legend({'class 1', 'class 0'})\n",
    "plt.title('prediction results of LR (error rate: %.03f)' % (error_rate))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#SVM with linear kernal\n",
    "clf = svm.SVC(kernel = 'linear', C=1)\n",
    "clf.fit(training_samples, training_labels)  \n",
    "predicted_labels = clf.predict(testing_samples)\n",
    "svm_error_rate = np.sum(predicted_labels != testing_labels)/len(testing_labels)\n",
    "print('SVM error rate: %.03f' % svm_error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot ground truth of testing samples\n",
    "plt.plot(testing_samples[testing_labels==1,0], testing_samples[testing_labels==1, 1],'ro')\n",
    "plt.plot(testing_samples[testing_labels==-1,0], testing_samples[testing_labels==-1, 1],'g^')\n",
    "plt.legend({'class 1', 'class -1'})\n",
    "plt.title('ground truth')\n",
    "\n",
    "#plot prediction results\n",
    "plt.figure()\n",
    "plt.plot(testing_samples[predicted_labels==1,0],testing_samples[predicted_labels==1, 1],'mo')\n",
    "plt.plot(testing_samples[predicted_labels==-1,0],testing_samples[predicted_labels==-1, 1],'c^')\n",
    "plt.legend({'class 1', 'class -1'})\n",
    "plt.title('prediction results of SVM (error rate: %.03f)' % (error_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot support vectors\n",
    "plt.figure()\n",
    "SVs = clf.support_vectors_\n",
    "nSV = clf.n_support_\n",
    "plt.plot(training_samples[training_labels==1,0],training_samples[training_labels==1, 1],'mo', label = 'class 1')\n",
    "plt.plot(training_samples[training_labels==-1,0],training_samples[training_labels==-1, 1],'c^', label='class -1')\n",
    "plt.plot(SVs[0:nSV[0],0], SVs[0:nSV[0],1],'g*', label='class 1 SVs')\n",
    "plt.plot(SVs[nSV[0]:,0], SVs[nSV[0]:,1],'b*', label='class -1 SVs')\n",
    "plt.legend()\n",
    "plt.title('Support vectors of linear kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support vector with Gaussian kernel (Radial Basis Kernel)\n",
    "\n",
    "clf = svm.SVC(kernel = 'rbf', C=0.1, gamma=0.5)\n",
    "clf.fit(training_samples, training_labels)  \n",
    "predicted_labels = clf.predict(testing_samples)\n",
    "svm_error_rate = np.sum(predicted_labels != testing_labels)/len(testing_labels)\n",
    "print('SVM error rate: %.03f' % svm_error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot support vectors\n",
    "plt.figure()\n",
    "SVs = clf.support_vectors_\n",
    "nSV = clf.n_support_\n",
    "plt.plot(training_samples[training_labels==1,0],training_samples[training_labels==1, 1],'mo', label = 'class 1')\n",
    "plt.plot(training_samples[training_labels==-1,0],training_samples[training_labels==-1, 1],'c^', label='class -1')\n",
    "plt.plot(SVs[0:nSV[0],0], SVs[0:nSV[0],1],'g*', label='class 1 SVs')\n",
    "plt.plot(SVs[nSV[0]:,0], SVs[nSV[0]:,1],'b*', label='class -1 SVs')\n",
    "plt.legend()\n",
    "plt.title('Support vectors of Gaussian kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare performances of NBC, LR, LDA, SVM for different training data size\n",
    "\n",
    "nbc_errors = []\n",
    "lr_errors = []\n",
    "lda_errors = []\n",
    "logR_errors = []\n",
    "svm_errors = []\n",
    "ts_start, ts_stop, ts_step = 30, 200, 10 #  training data size list\n",
    "for ts in range(ts_start, ts_stop, ts_step):\n",
    "    \n",
    "    #divide training and testing\n",
    "    np.random.shuffle(idx) \n",
    "    training_idx = idx[:int(ts)]\n",
    "    training_samples = samples[training_idx]\n",
    "    training_labels = labels[training_idx]\n",
    "\n",
    "    testing_idx = idx[int(ts):]\n",
    "    testing_samples = samples[testing_idx]\n",
    "    testing_labels = labels[testing_idx]\n",
    "    \n",
    "    #NBC\n",
    "    NBC.train(training_samples, training_labels)\n",
    "    predicted_labels, error_rate = NBC.test(testing_samples, testing_labels)\n",
    "    nbc_errors.append(error_rate)\n",
    "    \n",
    "    #LR\n",
    "    LR.train(training_samples, training_labels, show_w=False)\n",
    "    predicted_labels, error_rate = LR.test(testing_samples, testing_labels)\n",
    "    lr_errors.append(error_rate)\n",
    "    \n",
    "    #LDA\n",
    "    LDA.train(training_samples, training_labels)\n",
    "    predicted_labels, error_rate = LDA.test(testing_samples, testing_labels)\n",
    "    lda_errors.append(error_rate)\n",
    "    \n",
    "    #LogR\n",
    "    training_labels2 = training_labels.copy()\n",
    "    training_labels2[training_labels2==-1]=0\n",
    "    testing_labels2 = testing_labels.copy()\n",
    "    testing_labels2[testing_labels2==-1] = 0\n",
    "    LogR.train(training_samples, training_labels2)\n",
    "    predicted_labels, error_rate = LogR.test(testing_samples, testing_labels2)\n",
    "    logR_errors.append(error_rate)\n",
    "    \n",
    "    clf.fit(training_samples, training_labels)  \n",
    "    predicted_labels = clf.predict(testing_samples)\n",
    "    svm_error_rate = np.sum(predicted_labels != testing_labels)/len(testing_labels)\n",
    "    svm_errors.append(svm_error_rate)\n",
    "\n",
    "plt.plot(list(range(ts_start, ts_stop, ts_step)), nbc_errors, 'r-o')\n",
    "plt.plot(list(range(ts_start, ts_stop, ts_step)), lr_errors, 'g-^')\n",
    "plt.plot(list(range(ts_start, ts_stop, ts_step)), lda_errors, 'b-^')\n",
    "plt.plot(list(range(ts_start, ts_stop, ts_step)), logR_errors, 'c-^')\n",
    "plt.plot(list(range(ts_start, ts_stop, ts_step)), svm_errors, 'k-^')\n",
    "plt.legend({'NBC errors', 'LR errors', 'LDA errors', 'LogR errors','SVM errors'})\n",
    "plt.xlabel('training set size')\n",
    "plt.ylabel('error rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation on Watermelon 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "dict = sio.loadmat('watermelon')\n",
    "dataset = dict['dataset']\n",
    "samples = dataset[:, :8]\n",
    "labels = dataset[:, -1]\n",
    "labels = np.reshape(labels, -1) #change 2d vector (n, 1) to 1d vector (n,)\n",
    "labels[labels==0]=-1\n",
    "\n",
    "sample_num, sample_dim = samples.shape # N x D\n",
    "print(\"Sample number: %d, feature dimensionality: %d\" % (sample_num, sample_dim))\n",
    "\n",
    "col_names=[]\n",
    "for i in range(sample_dim):\n",
    "    str='feature%d'%(i+1)\n",
    "    col_names.append(str)\n",
    "col_names.append('labels')\n",
    "\n",
    "idx = list(range(sample_num)) # randomly shuffle indices\n",
    "np.random.shuffle(idx)  \n",
    "samples = samples[idx]\n",
    "labels = labels[idx]\n",
    "pandas.DataFrame(np.concatenate((samples, labels.reshape(sample_num,1)), axis=1), columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_num = 5\n",
    "num_per_fold = int(sample_num/fold_num) # 3\n",
    "\n",
    "nbc_errors = []\n",
    "lr_errors = []\n",
    "lda_errors = []\n",
    "logR_errors = []\n",
    "svm_errors = []\n",
    "\n",
    "NBC = TwoClassNaiveBayesClassifier(sample_dim)\n",
    "LR = LinearRegressor(sample_dim)\n",
    "LDA = LinearDiscriminantAnalysis(sample_dim)\n",
    "LogR = LogisticRegression(sample_dim)\n",
    "SVMC = svm.SVC(kernel = 'linear', C=1)\n",
    "\n",
    "for k in range(fold_num):\n",
    "    \n",
    "    #divide training and testing set\n",
    "    testing_idx = list(range(k*num_per_fold,(k+1)*num_per_fold))\n",
    "    testing_samples = samples[testing_idx]\n",
    "    testing_labels = labels[testing_idx]\n",
    "\n",
    "    training_samples = np.delete(samples, testing_idx, 0)\n",
    "    training_labels = np.delete(labels,testing_idx)\n",
    "    print('fold %d, testing samples:' % k, testing_idx)\n",
    "    print(testing_samples)\n",
    "    print('\\n')\n",
    "\n",
    "     #NBC\n",
    "    NBC.train(training_samples, training_labels)\n",
    "    predicted_labels, error_rate = NBC.test(testing_samples, testing_labels)\n",
    "    nbc_errors.append(error_rate)\n",
    "    \n",
    "    #LR\n",
    "    LR.train(training_samples, training_labels, show_w=False)\n",
    "    predicted_labels, error_rate = LR.test(testing_samples, testing_labels)\n",
    "    lr_errors.append(error_rate)\n",
    "    \n",
    "    #LDA\n",
    "    LDA.train(training_samples, training_labels)\n",
    "    predicted_labels, error_rate = LDA.test(testing_samples, testing_labels)\n",
    "    lda_errors.append(error_rate)\n",
    "    \n",
    "    #LogR\n",
    "    training_labels2 = training_labels.copy()\n",
    "    training_labels2[training_labels2==-1]=0\n",
    "    testing_labels2 = testing_labels.copy()\n",
    "    testing_labels2[testing_labels2==-1] = 0\n",
    "    LogR.train(training_samples, training_labels2, learning_rate=0.05, max_iterations=200)\n",
    "    predicted_labels, error_rate = LogR.test(testing_samples, testing_labels2)\n",
    "    logR_errors.append(error_rate)\n",
    "    \n",
    "    #SVM\n",
    "    SVMC.fit(training_samples, training_labels)  \n",
    "    predicted_labels = SVMC.predict(testing_samples)\n",
    "    svm_error_rate = np.sum(predicted_labels != testing_labels)/len(testing_labels)\n",
    "    svm_errors.append(svm_error_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NBC: %.03f'%np.mean(nbc_errors))\n",
    "print('LR: %0.03f'%np.mean(lr_errors))\n",
    "print('LDA: %.03f'%np.mean(lda_errors)) \n",
    "print('LogR: %.03f'%np.mean(logR_errors))\n",
    "print('SVM: %.03f'%np.mean(svm_errors))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: Because this is not a linear-separable dataset, so some of the points are incorrectly classified points with slackness."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
